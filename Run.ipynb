{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.robots import check_robots_txt\n",
    "from lib.shingling import *\n",
    "from lib.renderer import *\n",
    "from lib.crawler import crawl_url\n",
    "from lib.data import *\n",
    "from lib.normalize import normalize_corpus\n",
    "from engine import *\n",
    "\n",
    "import json\n",
    "\n",
    "from web.site_generator import build_site_data, build_sites\n",
    "from web.publish import Publish\n",
    "\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration File:\n",
      "\n",
      "bert_weight : 0.7\n",
      "browser_user_agent : Googlebot\n",
      "crawler_seed : https://data-science-blog.github.io/Customer-Data-Platform/\n",
      "embedding_size : 100\n",
      "i_type : bm25\n",
      "per_sec_crawl_rate : 1\n",
      "pr_weight : 0.7\n",
      "sg_gh_user : jroakes-locomotive\n",
      "sg_page_template : ---\n",
      "layout: post\n",
      "title:  {title}\n",
      "categories: [{topic}]\n",
      "---\n",
      "\n",
      "{content}\n",
      "\n",
      "\n",
      "sg_save_folder : files\n",
      "sg_sites : [{'topic': 'python software', 'org_name': 'python-software'}, {'topic': 'data science', 'org_name': 'data-science-blog'}, {'topic': 'search engine optimization', 'org_name': 'search-engine-optimization-blog'}]\n",
      "sim_weight : 0.7\n",
      "title_boost : 3\n",
      "transformer_model : distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "print('Configuration File:\\n')\n",
    "_ = [print(i,':', vars(cfg)[i]) for i in list(dir(cfg)) if '__' not in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://data-science-blog.github.io/Customer-Data-Platform/\n",
      "Crawling: https://data-science-blog.github.io/Data\n",
      "Crawling: https://data-science-blog.github.io/categories\n",
      "Crawling: https://data-science-blog.github.io/about\n",
      "Crawling: https://data-science-blog.github.io/\n",
      "Crawling: https://data-science-blog.github.io/Data/\n",
      "Crawling: https://data-science-blog.github.io/Consistency-Database-Systems/\n",
      "Crawling: https://data-science-blog.github.io/Big-Data\n",
      "Crawling: https://python-software.github.io/Eric-Software\n",
      "Crawling: https://data-science-blog.github.io/Dataintensive-Computing/\n",
      "Crawling: https://data-science-blog.github.io/Big-Data/\n",
      "Crawling: https://data-science-blog.github.io/Black-Swan-Data/\n",
      "Crawling: https://data-science-blog.github.io/Berkeley-Institute-For-Data-Science/\n",
      "Crawling: https://data-science-blog.github.io/Coding-Bootcamp/\n",
      "Crawling: https://data-science-blog.github.io/Chief-Data-Officer/\n",
      "Crawling: https://data-science-blog.github.io/Committee-On-Data-For-Science-And-Technology/\n",
      "Crawling: https://data-science-blog.github.io/page2/\n",
      "Crawling: https://python-software.github.io/Core-Python-Programming\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Google-Custom-Search\n",
      "Crawling: https://python-software.github.io/Comparison-Of-Integrated-Development-Environments\n",
      "Crawling: https://python-software.github.io/Intel-Parallel-Studio\n",
      "Crawling: https://data-science-blog.github.io/Committee-On-Data-For-Science-And-Technology\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Contextual-Advertising\n",
      "Crawling: https://python-software.github.io/History-Of-Python\n",
      "Crawling: https://data-science-blog.github.io/Customer-Data-Platform\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Audio-Search-Engine\n",
      "Crawling: https://data-science-blog.github.io/Berkeley-Institute-For-Data-Science\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Google-Search\n",
      "Crawling: https://python-software.github.io/Anaconda-Python-Distribution\n",
      "Crawling: https://python-software.github.io/Core-Python-Programming/\n",
      "Crawling: https://python-software.github.io/\n",
      "Crawling: https://python-software.github.io/History-Of-Python/\n",
      "Crawling: https://python-software.github.io/about\n",
      "Crawling: https://python-software.github.io/categories\n",
      "Crawling: https://python-software.github.io/Comparison-Of-Integrated-Development-Environments/\n",
      "Crawling: https://python-software.github.io/Eric-Software/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/about\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Fulltext-Search/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Google-Search/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/categories\n",
      "Crawling: https://python-software.github.io/Circuitpython/\n",
      "Crawling: https://python-software.github.io/Idle/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Danny-Sullivan-Technologist/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Clean-Url/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Clean-Url\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Barry-Schwartz-Technologist/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Archie-Search-Engine/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Google-Custom-Search/\n",
      "Crawling: https://data-science-blog.github.io/Consistency-Database-Systems\n",
      "Crawling: https://data-science-blog.github.io/Black-Swan-Data\n",
      "Crawling: https://python-software.github.io/Activestate/\n",
      "Crawling: https://python-software.github.io/Biopython/\n",
      "Crawling: https://python-software.github.io/Intel-Parallel-Studio/\n",
      "Crawling: https://python-software.github.io/page2/\n",
      "Crawling: https://python-software.github.io/Anaconda-Python-Distribution/\n",
      "Crawling: https://python-software.github.io/Ironpython/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Dragonfly-Search-Engine/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Contextual-Advertising/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/page2/\n",
      "Crawling: https://search-engine-optimization-blog.github.io/Audio-Search-Engine/\n",
      "Crawling: https://data-science-blog.github.io/Chief-Data-Officer\n"
     ]
    }
   ],
   "source": [
    "crawler = Crawler()\n",
    "crawler.crawl('https://data-science-blog.github.io/Customer-Data-Platform/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "newcrawler = copy.deepcopy(crawler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IPKernelApp': {'connection_file': 'C:\\\\Users\\\\jroak\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-e9c54d4e-dbb3-4ca4-a3a2-a23bce777dfb.json'}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ipython().config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7c9e0955c7c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcrawler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\AnacondaProjects\\TechSEO Crawler\\engine.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRenderHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc_hash\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaProjects\\TechSEO Crawler\\lib\\renderer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, html)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\techseo\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_done_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_run_until_complete_cb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnew_task\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancelled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\techseo\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This event loop is already running'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "crawler.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = Indexer(crawler)\n",
    "indexer.build_index()\n",
    "indexer.build_bert_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'python programming'\n",
    "df = indexer.search_index(search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://locomotive.agency/\"\n",
    "page_data = crawl_url(url)\n",
    "print(\"## Status \" + \"#\"*20 + \"\\n\")\n",
    "print(page_data['status'])\n",
    "print(\"\\n## Meta \" + \"#\"*20 + \"\\n\")\n",
    "print(json.dumps(page_data['meta'], indent=4))\n",
    "print(\"\\n## Content \" + \"#\"*20 + \"\\n\")\n",
    "print(page_data['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shingling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content1 = \"\"\"Many packages don't create a build for every single release which forces your pip to build from source. If you're happy to use the latest pre-compiled binary version, use --only-binary :all: to allow pip to use an older binary version.\"\"\"\n",
    "content2 = \"\"\"Most packages don't create a build for every single release which forces your pip to build from source. If you're happy to use the latest pre-compiled binary version, use --only-binary :all: to allow pip to use an older binary version.\"\"\"\n",
    "content3 = \"\"\"The C++ Build Tools allow you to build C++ libraries and applications targeting Windows desktop. They are the same tools that you find in Visual Studio 2019, Visual Studio 2017, and Visual Studio 2015 in a scriptable standalone installer. Now you only need to download the MSVC compiler toolset you need to build C++ projects on your build servers.\"\"\"\n",
    "\n",
    "\n",
    "hashdb = HashLookup()\n",
    "\n",
    "hashdb.add_hash('content1', content1)\n",
    "hashdb.add_hash('content2', content2)\n",
    "hashdb.add_hash('content3', content3)\n",
    "\n",
    "print(\"## Hashes \" + \"#\"*20 + \"\\n\")\n",
    "print(hashdb.get_hash('content1')[:5])\n",
    "print(hashdb.get_hash('content2')[:5])\n",
    "print(hashdb.get_hash('content3')[:5])\n",
    "print(\"\\n## Length \" + \"#\"*20 + \"\\n\")\n",
    "print(len(hashdb))\n",
    "print(\"\\n## Similarity \" + \"#\"*20 + \"\\n\")\n",
    "print(hashdb.get_similarity_df(content2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ['urla', 'urlb', 'urlc', 'urld', 'urle']\n",
    "link_tuples = [('urla','urlb'), ('urlc','urlb'), ('urla','urle'), ('urle','urla'), ('urlc','urlb'), ('urld','urle'), ('urle','urlb')]\n",
    "\n",
    "pr_valid = {'url': {0: 'urlb', 1: 'urle', 2: 'urla', 3: 'urld', 4: 'urlc'}, 'score': {0: 0.3625498007448575, 1: 0.2544205750109898, 2: 0.19976269190396267, 3: 0.09163346617009499, 4: 0.09163346617009499}}\n",
    "df = build_pagerank_df(url_list, link_tuples)\n",
    "\n",
    "print(\"## PageRank \" + \"#\"*20 + \"\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.bert import *\n",
    "\n",
    "queries = ['trim a chrismas tree', 'jog on a path', 'kindle ebook', 'italian restaurant', 'internet landing page']\n",
    "ngrams = ['decorate a tree', 'run on a road', 'electric book', 'cafe in italy', 'website homepage']\n",
    "\n",
    "bert = BERT(dims=None)\n",
    "bert.add_terms(ngrams)\n",
    "\n",
    "for q in queries:\n",
    "    best, sim = bert.get_most_similar(q)\n",
    "    print(\"Query: {} {} ===> Best Guess: {} ({})\".format(q, ' '*(25-len(q)), best, round(sim,4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
